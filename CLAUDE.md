# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**mcp-toolse** is an AI Tools Service built on FastMCP + FastAPI that integrates multiple AI tools and models, providing a unified tool invocation interface through the Model Context Protocol (MCP). The service supports dual transport modes: STDIO (for local communication) and SSE (Server-Sent Events for web-based communication).

### MediaCrawler Integration

This project integrates **media_crawler** functionality by extracting its crawler implementations into our service architecture:

- **Crawler Modules**: `app/crawler/platforms/` - Platform-specific crawlers (Bilibili, Xiaohongshu, Douyin, Kuaishou, Weibo, Tieba, Zhihu)
- **Integration Approach**: Direct integration with parameterized configuration instead of global config
- **Configuration**: Unified Pydantic-based configuration in `app/config/settings.py`
- **Database**: PostgreSQL with models in `app/providers/models/`
- **API Layer**: MCP tools exposed via `app/api/endpoints/mcp/`

**Key Improvements**:
- âœ… Parameterized configuration (no global state)
- âœ… Concurrent-safe (no race conditions)
- âœ… Type-safe with Pydantic validation
- âœ… Unified provider pattern (logger, cache, database)

## Development Commands

### Environment Setup
```ba
# Install dependencies using Poetry
./deploy/dev.sh setup

# Update dependencies
./deploy/dev.sh update
```

### Running the Service

```bash
# Start both STDIO and SSE servers (default)
./deploy/dev.sh start
# or
poetry run python main.py --transport both

# Start only STDIO server
./deploy/dev.sh start-stdio
# or
poetry run python main.py --transport stdio

# Start only SSE server
./deploy/dev.sh start-sse
# or
poetry run python main.py --transport sse

# Start production server with Uvicorn
./deploy/dev.sh start-prod
```

**Important**: The SSE server runs on `http://0.0.0.0:9090/sse` (port configured in `app/config/settings.py`)

### Testing

```bash
# Run all tests
./deploy/dev.sh test
# or
poetry run pytest tests/ -v

# Test MCP tools
./deploy/dev.sh test-tools

# Test SSE connection
./deploy/dev.sh test-sse
```

### Code Quality

```bash
# Format code (Black + isort)
./deploy/dev.sh format

# Check code quality (flake8 + mypy)
./deploy/dev.sh check
```

### Docker Deployment

```bash
# Build Docker image
./deploy/dev.sh build

# Start Docker services
./deploy/dev.sh docker

# Stop Docker services
./deploy/dev.sh docker-stop
```

## ğŸ—ï¸ API Architecture Rules

### **CRITICAL: Unified API Layer Pattern**

**All API-related functionality MUST be placed in `app/api/endpoints/`** - No exceptions!

#### Rule 1: No Separate Admin Routes
âŒ **WRONG**: Creating routes in `app/admin/routes/`
âœ… **CORRECT**: Creating endpoints in `app/api/endpoints/admin/`

**Rationale**:
- Unified endpoint registration through `BaseEndpoint`
- Consistent HTTP routing via Starlette
- Single source of truth for all API routes
- Easier maintenance and debugging

#### Rule 2: All Endpoints Must Extend BaseEndpoint

Every endpoint class must:
1. Extend `app.mcp.base_endpoint.BaseEndpoint`
2. Implement `register_routes()` - return list of Starlette routes
3. Implement `register_mcp_tools()` - register FastMCP tools (can be empty)
4. Be registered in `app.api_service.py:auto_discover_endpoints()`

**Example**:
```python
# app/api/endpoints/admin/config_endpoint.py
from app.mcp.base_endpoint import BaseEndpoint

class ConfigEndpoint(BaseEndpoint):
    prefix = "/config"
    tags = ["é…ç½®ç®¡ç†"]

    def register_routes(self):
        from fastapi import APIRouter
        router = APIRouter(prefix=self.prefix, tags=self.tags)

        @router.get("/platforms")
        async def get_platforms():
            # Handler logic
            pass

        return router.routes

    def register_mcp_tools(self, app):
        # Optional: register MCP tools
        pass
```

#### Rule 3: Endpoint Registration

All endpoints are registered in `app/api_service.py:auto_discover_endpoints()`:

```python
# Platform endpoints (conditional registration based on enabled_platforms)
from app.api.endpoints.mcp import BilibiliEndpoint, XiaohongshuEndpoint, ...
if "bili" in enabled_platforms:
    endpoint_registry.register(BilibiliEndpoint())

# Management endpoints (always registered)
from app.api.endpoints.login import LoginEndpoint
from app.api.endpoints.admin import ConfigEndpoint, StatusEndpoint
endpoint_registry.register(LoginEndpoint())
endpoint_registry.register(ConfigEndpoint())
endpoint_registry.register(StatusEndpoint())
```

#### Current Endpoint Structure

```
app/api/endpoints/
â”œâ”€â”€ mcp/              # Platform MCP tools
â”‚   â”œâ”€â”€ bilibili.py   # Bilibiliçˆ¬è™«å·¥å…·
â”‚   â”œâ”€â”€ xiaohongshu.py
â”‚   â”œâ”€â”€ douyin.py
â”‚   â”œâ”€â”€ kuaishou.py
â”‚   â”œâ”€â”€ weibo.py
â”‚   â”œâ”€â”€ tieba.py
â”‚   â””â”€â”€ zhihu.py
â”œâ”€â”€ login/            # Login management
â”‚   â””â”€â”€ login_endpoint.py
â””â”€â”€ admin/            # Admin & monitoring
    â”œâ”€â”€ config_endpoint.py   # Config management
    â””â”€â”€ status_endpoint.py   # Status monitoring
```

#### Migration History (2025-01)

**Migrated from `app/admin/routes/` to `app/api/endpoints/admin/`:**
- âœ… `login.py` â†’ `app/api/endpoints/login/login_endpoint.py`
- âœ… `config.py` â†’ `app/api/endpoints/admin/config_endpoint.py`
- âœ… `status.py` â†’ `app/api/endpoints/admin/status_endpoint.py`
- ğŸ—‘ï¸ Deleted: `app/admin/routes/` directory (obsolete)

### **CRITICAL: Provider Usage Rules**

**Rule 4: Standardized Logger and Cache Usage**

All code MUST use the centralized provider modules for logging and caching.

**Rule 5: PostgreSQL Database Storage Standards**

All database operations MUST follow these standards:

1. **Database Choice**: Use PostgreSQL exclusively (not SQLite, MySQL, or others)
2. **Model Location**: All database models MUST be placed in `app/providers/models/`
3. **Configuration**: Database settings are in `app/config/settings.py` â†’ `DatabaseConfig` class
4. **Connection Management**: Use `app.database.db_session.get_session()` for async sessions

âŒ **WRONG**: Models scattered in different directories
```python
# app/database/models.py  # âŒ Old location
# app/crawler/models.py   # âŒ Wrong location
```

âœ… **CORRECT**: Centralized model definitions
```python
# app/providers/models/bilibili.py
from sqlalchemy import Column, String, Integer, Text
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class BilibiliVideo(Base):
    __tablename__ = "bilibili_videos"

    video_id = Column(String(50), primary_key=True)
    title = Column(String(500))
    view_count = Column(Integer)
    # ... more fields
```

**Usage in Store Layer**:
```python
from app.providers.models.bilibili import BilibiliVideo
from app.database.db_session import get_session

async def store_video(video_data: Dict):
    async with get_session() as session:
        video = BilibiliVideo(**video_data)
        session.add(video)
        await session.commit()
```

**Why**:
- Single source of truth for data schemas
- Easy to manage migrations
- Better IDE support and type checking
- Consistent database access patterns

**Rule 6: Unified Configuration System**

All crawler configuration MUST be unified in `app/config/settings.py` using platform-specific Pydantic models.

**Problem**: Original architecture had two config locations:
- `app/crawler/config/` - Platform-specific settings (scattered)
- `app/config/settings.py` - App settings (centralized)

**Solution**: Delete `app/crawler/config/` and merge everything into `app/config/settings.py` with per-platform configuration classes.

âŒ **WRONG**: Separate config files per platform
```python
# app/crawler/config/bilibili.py  # âŒ Delete this
BILI_MAX_NOTES = 20
BILI_HEADLESS = True
```

âœ… **CORRECT**: Unified Pydantic configuration
```python
# app/config/settings.py
from pydantic import BaseModel

class BilibiliConfig(BaseModel):
    """Bilibiliå¹³å°é…ç½®"""
    max_notes: int = 20
    enable_comments: bool = True
    max_comments_per_note: int = 50
    headless: bool = True
    save_data_option: str = "json"  # json/csv/db
    login_type: str = "qrcode"  # qrcode/cookie

    # å¹³å°ç‰¹å®šè®¾ç½®
    video_quality: str = "1080p"
    download_cover: bool = True

class GlobalSettings(BaseSettings):
    # ... other configs
    bilibili: BilibiliConfig = BilibiliConfig()
    xiaohongshu: XiaohongshuConfig = XiaohongshuConfig()
    douyin: DouyinConfig = DouyinConfig()
    # ... more platforms
```

**Usage Pattern**:
```python
from app.config.settings import global_settings

# Access platform config
bili_config = global_settings.bilibili
max_notes = bili_config.max_notes  # 20
headless = bili_config.headless  # True

# Pass config to crawler
crawler = BilibiliCrawler(config=bili_config)
await crawler.search(keywords="Python", max_notes=bili_config.max_notes)
```

**Benefits**:
1. **Parameterized Configuration**: Each request can have different settings
2. **Type Safety**: Pydantic validation ensures correct types
3. **Environment Overrides**: Can override via env vars (e.g., `BILI_MAX_NOTES=50`)
4. **Single Source of Truth**: One place to manage all settings
5. **No Global State**: No race conditions from shared config objects

**Migration Checklist**:
- ğŸ”´ Delete `app/crawler/config/` directory
- ğŸ”´ Create platform config classes in `settings.py` (start with Bilibili)
- ğŸ”´ Update all crawler usage to pass config instances
- ğŸ”´ Remove `import config` from all crawler files

#### Logger Usage
âŒ **WRONG**: Using custom loggers or utils.logger
```python
import logging
logger = logging.getLogger(__name__)  # âŒ Don't do this

from tools import utils
utils.logger.info("message")  # âŒ Don't do this
```

âœ… **CORRECT**: Use app.providers.logger
```python
from app.providers.logger import get_logger

logger = get_logger()
logger.info("message")
logger.error(f"Error occurred: {e}")
```

**Why**:
- Centralized logging configuration
- Consistent log formatting across all modules
- Easy to modify logging behavior globally
- Proper log rotation and file handling

#### Cache Usage
âŒ **WRONG**: Direct Redis or custom cache implementation
```python
import redis
redis_client = redis.Redis()  # âŒ Don't do this
```

âœ… **CORRECT**: Use app.providers.cache
```python
from app.providers.cache import get_cache

cache = get_cache()
await cache.set("key", "value", expire=3600)
value = await cache.get("key")
```

**Why**:
- Connection pooling and reuse
- Automatic serialization/deserialization
- Consistent error handling
- Easy to switch cache backends

#### Enforcement
These rules apply to:
- âœ… All new code
- âœ… All refactored code
- âœ… Platform crawlers (`app/crawler/platforms/*/`)
- âœ… API endpoints (`app/api/endpoints/*/`)
- âœ… Services and utilities

**Migration Required**:
- ğŸ”´ `app/crawler/store/bilibili/_store_impl.py` - Uses old imports (line 27, 28, 32)
- ğŸ”´ `app/crawler/store/bilibili/bilibilli_store_media.py` - Uses `utils.logger` (line 68)

## Architecture

### Core Concepts

This application uses a **dual-layer architecture** that integrates FastMCP (for MCP tool protocol) with Starlette (for HTTP routing):

1. **FastMCP Layer**: Provides MCP protocol support for tool invocation via STDIO and SSE
2. **Starlette Layer**: Provides HTTP/REST API endpoints alongside MCP endpoints

### Key Components

#### 1. Endpoint Registration System (`app/core/base_endpoint.py`)

The codebase uses a unified endpoint registration pattern where each endpoint:
- Extends `BaseEndpoint` abstract class
- Registers both Starlette HTTP routes AND FastMCP tools
- Is auto-discovered and registered via `endpoint_registry`

**Pattern to follow when adding new endpoints**:
```python
class MyEndpoint(BaseEndpoint):
    def __init__(self):
        super().__init__(prefix="/my-endpoint", tags=["My Category"])

    def register_routes(self) -> List[Route]:
        # Define Starlette HTTP routes
        async def my_handler(request: Request) -> JSONResponse:
            # Handler logic
            pass

        return [
            self._create_route("/action", my_handler, ["POST"])
        ]

    def register_mcp_tools(self, app: FastMCP):
        # Define MCP tools
        @app.tool()
        async def my_tool(param: str) -> str:
            """Tool description"""
            # Tool logic
            pass

        self._add_tool_info("my_tool", "Tool description")
```

#### 2. Application Initialization (`app/api_service.py`)

The `create_app()` function:
- Initializes logging
- Creates FastMCP application
- Auto-discovers endpoints (add new endpoints in `auto_discover_endpoints()`)
- Patches FastMCP's SSE runner to integrate Starlette routes
- Registers service info tools

**To add a new endpoint**: Edit `auto_discover_endpoints()` in `app/api_service.py:110-133`:
```python
from app.api.endpoints.my_endpoint import MyEndpoint
endpoint_registry.register(MyEndpoint())
```

#### 3. Configuration System (`app/config/settings.py`)

**âš ï¸ CRITICAL KNOWN ISSUE**: The current configuration injection mechanism has a race condition bug in concurrent scenarios. See "Configuration System Issues" section below.

Configuration is managed via:
- Environment variables (`.env` file) - Primary configuration source
- Pydantic Settings with default values - `GlobalSettings` class
- NO YAML files used (legacy code references them but files don't exist)

Configuration hierarchy:
```
GlobalSettings (root)
â”œâ”€â”€ AppConfig - Application settings (name, port, debug, env, version)
â”œâ”€â”€ JWTConfig - Authentication settings
â”œâ”€â”€ DatabaseConfig - PostgreSQL settings
â”œâ”€â”€ RedisConfig - Redis cache settings
â”œâ”€â”€ LoggerConfig - Logging configuration
â”œâ”€â”€ SidecarConfig - MediaCrawler sidecar service settings
â””â”€â”€ PlatformSettings - Platform-specific settings (enabled platforms, login types, etc.)
```

Environment variable naming:
- **Current implementation uses SINGLE underscore**: `APP_PORT`, `DB_HOST`, `REDIS_PORT`
- **âš ï¸ BUG**: `.env` file uses DOUBLE underscore (`APP__PORT`), causing `_override_from_env()` to fail
- See "Configuration System Issues" section for details

#### 4. Main Entry Point (`main.py`)

Supports three transport modes via `--transport` argument:
- `stdio`: STDIO-based MCP communication
- `sse`: SSE-based web communication
- `both`: Run both concurrently (default)

### Project Structure

```
app/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ endpoints/          # Endpoint implementations
â”‚       â”œâ”€â”€ mcp/            # MCP platform endpoints
â”‚       â”‚   â”œâ”€â”€ base.py         # Base platform endpoint
â”‚       â”‚   â”œâ”€â”€ xiaohongshu.py  # å°çº¢ä¹¦ MCP tools
â”‚       â”‚   â”œâ”€â”€ douyin.py       # æŠ–éŸ³ MCP tools
â”‚       â”‚   â”œâ”€â”€ bilibili.py     # Bç«™ MCP tools
â”‚       â”‚   â”œâ”€â”€ kuaishou.py     # å¿«æ‰‹ MCP tools
â”‚       â”‚   â”œâ”€â”€ weibo.py        # å¾®åš MCP tools
â”‚       â”‚   â”œâ”€â”€ tieba.py        # è´´å§ MCP tools
â”‚       â”‚   â””â”€â”€ zhihu.py        # çŸ¥ä¹ MCP tools
â”‚       â”œâ”€â”€ sidecar/        # Sidecar HTTP endpoints
â”‚       â”‚   â””â”€â”€ sidecar_endpoint.py  # Sidecar management API
â”‚       â””â”€â”€ login/          # Login management endpoints
â”‚           â””â”€â”€ login_endpoint.py    # Login & verification API
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py         # Configuration management (YAML files don't exist)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ base_endpoint.py    # Endpoint base class & registry
â”‚   â”œâ”€â”€ browser_pool.py     # Browser instance pooling
â”‚   â”œâ”€â”€ session_manager.py  # Cookie & session management
â”‚   â”œâ”€â”€ media_crawler_service.py  # Sidecar service implementation
â”‚   â””â”€â”€ client/
â”‚       â””â”€â”€ media_crawler_client.py  # HTTP client for sidecar
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ logger.py           # Logging configuration
â”‚   â”œâ”€â”€ authentication.py   # Auth providers
â”‚   â””â”€â”€ models/             # Data models
â”œâ”€â”€ api_service.py          # MCP application factory
â””â”€â”€ admin.py                # Admin web interface

media_crawler/              # Git submodule (DO NOT MODIFY)
â”œâ”€â”€ main.py                 # MediaCrawler entry point
â”œâ”€â”€ config/                 # MediaCrawler configs (global state!)
â”œâ”€â”€ media_platform/         # Platform crawlers (xhs, dy, ks, bili, etc.)
â”œâ”€â”€ database/               # Database models
â””â”€â”€ store/                  # Data storage implementations

deploy/
â”œâ”€â”€ docker-compose.yml      # Unified Docker services
â”œâ”€â”€ Dockerfile              # Main service Docker image
â””â”€â”€ dev.sh                  # Development scripts
```

## Important Implementation Details

### FastMCP + Starlette Integration

The application **patches FastMCP's SSE runner** to serve both MCP SSE endpoints AND Starlette HTTP routes on the same server. This is done in `_patch_fastmcp_sse()` (app/api_service.py:50-107).

**Key insight**: All endpoint routes are collected and mounted alongside MCP routes:
```python
routes = [
    Route("/sse", endpoint=handle_sse),           # MCP SSE endpoint
    Mount("/messages/", app=sse.handle_post_message),  # MCP messages
] + api_routes  # HTTP API routes from all endpoints
```

### Tool Discovery Pattern

Tools are not manually registered. Instead:
1. Each endpoint class implements `register_mcp_tools(app: FastMCP)`
2. `endpoint_registry.register_all_mcp_tools(app)` calls each endpoint's method
3. Tools use FastMCP's `@app.tool()` decorator

### Logging

Logging is initialized once in `create_app()` using `init_logger()` from `app/providers/logger.py`. Access the logger anywhere via:
```python
from app.providers.logger import get_logger
get_logger().info("Message")
```

## Development Workflow

### Adding a New Tool Category

1. Create endpoint file in `app/api/endpoints/my_category.py`
2. Implement tool logic in `app/core/tools/my_category.py` (if complex)
3. Create endpoint class extending `BaseEndpoint`
4. Implement `register_routes()` and `register_mcp_tools()`
5. Register in `auto_discover_endpoints()` in `app/api_service.py`

### Configuration Changes

âš ï¸ **Note**: The configuration system has known issues. See "Configuration System Issues" section below before making changes.

To modify configuration:
1. Edit `.env` file with your environment variables
2. Add new fields to appropriate classes in `app/config/settings.py`
3. Update `_override_from_env()` function if needed (ensure variable naming matches `.env`)
4. Update README.md to document new configuration options

**Current issue**: YAML files (`dev.yaml`, `prod.yaml`) don't exist despite being referenced in code.

### Database & Redis

Database (PostgreSQL) and Redis are configured but initialization is optional:
- `init_database()` - Tortoise ORM initialization
- `init_redis()` - Redis client initialization

These must be called manually if needed (not auto-initialized).

## Python Environment

- **Python**: 3.11+
- **Package Manager**: Poetry 2.0+
- **Dependencies**: See `pyproject.toml`

## Code Quality Standards

### Type Checking (mypy)
The project uses strict mypy configuration:
- All functions must have type hints
- Untyped definitions are disallowed
- See `[tool.mypy]` in `pyproject.toml` for full config

### Formatting
- **Black**: Line length 88, Python 3.11 target
- **isort**: Black-compatible profile

### Testing
- **pytest**: Tests in `tests/` directory
- Use `pytest-asyncio` for async tests
- Run with: `poetry run pytest tests/ -v`

## Common Patterns

### Error Handling in Endpoints
```python
async def my_handler(request: Request) -> JSONResponse:
    try:
        body = await self._parse_json_body(request)
        # Process request
        return self._create_json_response(result)
    except Exception as e:
        get_logger().error(f"Error: {e}")
        return self._create_json_response(str(e), 500)
```

### MCP Tool Registration
```python
@app.tool()
async def my_tool(param: str) -> str:
    """Clear description of what the tool does"""
    # Implementation
    return result

# Track the tool
self._add_tool_info("my_tool", "Clear description")
```

## Transport Modes

### STDIO Mode
- Used for local/desktop applications
- Direct process communication
- Configuration: MCP client config files reference this service

### SSE Mode
- Used for web-based applications
- Server-Sent Events for real-time updates
- Endpoint: `http://0.0.0.0:9090/sse`
- Also serves HTTP API routes on same server

### Both Mode (Default)
- Runs STDIO and SSE concurrently using `asyncio.gather()`
- Allows simultaneous local and web access

## âš ï¸ Configuration System Issues

### Critical Issue #1: Configuration Injection Race Condition

**Location**: `app/config/settings.py:415-458` (`MediaCrawlerConfigAdapter.inject_config`)

**Problem**: The configuration adapter directly modifies `media_crawler`'s global `config.py` module, which causes race conditions in concurrent scenarios.

**Root Cause**:
```python
# In MediaCrawlerConfigAdapter.inject_config()
import config as mc_config  # This imports a cached singleton module
mc_config.PLATFORM = crawler_config.platform  # Modifies global state!
``

Since Python modules are singletons (imported once and cached), all concurrent requests share the same `config` object. In a sidecar service handling multiple crawl requests simultaneously, configurations will overwrite each other.

**Concurrent Scenario Example**:
```
Time  | Request A (xhs, keywords="AI")  | Request B (dy, keywords="Tech")
------|----------------------------------|----------------------------------
T1    | inject_config(xhs, "AI")         |
      | config.PLATFORM = "xhs"          |
      | config.KEYWORDS = "AI"           |
T2    |                                  | inject_config(dy, "Tech")
      |                                  | config.PLATFORM = "dy" â† Overwrites!
      |                                  | config.KEYWORDS = "Tech" â† Overwrites!
T3    | Starts crawling...               |
      | Uses PLATFORM="dy", KEYWORDS="Tech" | â† BUG: Should be xhs/AI!
```

**Impact**: In production sidecar service with browser pooling, this will cause:
- Wrong platform being crawled
- Wrong keywords being searched
- Data corruption and user confusion

**Recommended Fix** (Priority: P0 - Critical):

**Option A - Environment Variable Isolation** (Recommended):
```python
def inject_config_via_env(self, crawler_config: CrawlerConfig) -> dict:
    """Create isolated environment for each crawl task"""
    env = os.environ.copy()
    env['MC_PLATFORM'] = crawler_config.platform
    env['MC_CRAWLER_TYPE'] = crawler_config.crawler_type
    env['MC_KEYWORDS'] = crawler_config.keywords or ''
    # ... more configs
    return env

# In media_crawler_service.py
async def _execute_crawl(self, crawler_config: CrawlerConfig):
    env = self.config_adapter.inject_config_via_env(crawler_config)
    # Run crawler in separate process with isolated env
    process = await asyncio.create_subprocess_exec(
        sys.executable, "-m", "media_crawler.main",
        env=env,  # Isolated configuration!
        cwd=str(MEDIA_CRAWLER_PATH)
    )
```

**Option B - Fork MediaCrawler for Instance-based Config** (Not recommended):
Requires modifying the `media_crawler` submodule to use instance-based configuration instead of global config, which violates the "don't modify submodule" principle.

---

### Issue #2: Environment Variable Naming Mismatch

**Location**: `.env` file vs `app/config/settings.py:333-380` (`_override_from_env()`)

**Problem**: Environment variable names don't match between configuration file and code.

**Mismatch Table**:

| Configuration | .env File | _override_from_env() | Works? |
|---------------|-----------|---------------------|--------|
| APP Port      | `APP__PORT=9090` | `os.getenv('APP_PORT')` | âŒ No |
| DB Host       | `DB__HOST=localhost` | `os.getenv('DB_HOST')` | âŒ No |
| Enabled Platforms | `ENABLED__PLATFORMS=all` | `os.getenv('ENABLED_PLATFORMS')` | âŒ No |

**Root Cause**:
- `.env` uses **double underscore** (`__`) - Pydantic nested env var convention
- Code uses **single underscore** (`_`) - Traditional env var naming
- Result: `_override_from_env()` reads nothing and has no effect

**Impact**: Environment variables cannot override default settings, making configuration inflexible.

**Recommended Fix** (Priority: P0 - Critical):

**Choose ONE naming convention and apply consistently:**

**Option A - Single Underscore** (Simpler, recommended):
```bash
# .env
APP_ENV=dev
APP_PORT=9090
APP_DEBUG=true
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=password
DB_NAME=mcp_tools_db
REDIS_HOST=localhost
REDIS_PORT=6379
SIDECAR_URL=http://localhost:8001
ENABLED_PLATFORMS=all
```

**Option B - Double Underscore** (Pydantic standard):
```bash
# .env (following Pydantic nested delimiter convention)
APP__ENV=dev
APP__PORT=9090
DATABASE__HOST=localhost
DATABASE__PORT=5432
SIDECAR__URL=http://localhost:8001
PLATFORMS__ENABLED_PLATFORMS=all
```

Then update `_override_from_env()` to match:
```python
def _override_from_env(settings: GlobalSettings) -> None:
    # Match the naming in .env!
    if port := os.getenv('APP_PORT'):  # or 'APP__PORT'
        settings.app.port = int(port)
```

---

### Issue #3: Missing Configuration Fields

**Location**: `app/config/settings.py` - `AppConfig` and `SidecarConfig`

**Problem**: README and `main.py` reference configuration fields that don't exist in `settings.py`:

- `ADMIN_PORT` - Used in `main.py:73-96` but not in `AppConfig`
- `SIDECAR_PORT` - Mentioned in README but not in `SidecarConfig`

**Impact**: These ports are hardcoded in `main.py` instead of being configurable.

**Recommended Fix** (Priority: P1 - High):

```python
# In settings.py
class AppConfig(BaseModel):
    name: str = 'mcp-toolse'
    port: int = 9090          # MCP service port
    admin_port: int = 9091    # â† Add this
    debug: bool = True
    env: str = 'dev'
    version: str = '1.0.0'
    auto_reload: bool = False

class SidecarConfig(BaseModel):
    url: str = 'http://localhost:8001'
    port: int = 8001          # â† Add this
    timeout: float = 300.0
    # ... rest of config
```

Then update `main.py`:
```python
# OLD: args.admin_port (hardcoded default 9091)
# NEW: global_settings.app.admin_port
await run_admin_service(global_settings.app.admin_port)
```

---

### Issue #4: YAML Files Referenced But Don't Exist

**Location**: `app/config/settings.py:299-331` (`load_config()`)

**Problem**: Code attempts to load `dev.yaml` and `prod.yaml`, but these files don't exist in `app/config/` directory.

**Current Code**:
```python
def load_config() -> GlobalSettings:
    yaml_file_path = config_dir / f"{app_env}.yaml"
    if yaml_file_path.exists():  # â† Always False!
        # YAML loading logic (never executed)
```

**Impact**: Dead code that adds complexity without providing value.

**Recommended Fix** (Priority: P2 - Medium):

**Option A - Remove YAML Logic** (Recommended):
Simplify to pure Pydantic + environment variables:
```python
def load_config() -> GlobalSettings:
    """Load configuration from Pydantic defaults + env vars"""
    settings = GlobalSettings()  # Loads from .env via Pydantic
    _override_from_env(settings)  # Explicit overrides
    return settings
```

**Option B - Create YAML Files**:
If you want to keep YAML support, create the files. But this adds complexity for little benefit.

---

### Issue #5: Duplicate and Inconsistent .env Entries

**Location**: `.env` file lines 39-44

**Problem**: Duplicate configuration with inconsistent naming:
```bash
# Lines 1-12: New format with double underscores
ENABLED__PLATFORMS=all

# Lines 39-44: Old format with single underscores (DUPLICATE!)
ENABLED_PLATFORMS=xhs,tieba,ks,bili,wb,zhihu
MEDIA_CRAWLER_MAX_NOTES=15
MEDIA_CRAWLER_ENABLE_COMMENTS=true
```

**Impact**: Confusing, conflicting configuration that's hard to maintain.

**Recommended Fix** (Priority: P1 - High):

Remove lines 39-44 from `.env` file. Keep only one set of configuration using consistent naming.

---

### Configuration Changes Checklist

When modifying configuration:

1. **Environment Variables**: Update `.env` file with correct naming convention
2. **Settings Classes**: Add/modify fields in `app/config/settings.py`
3. **Override Function**: Update `_override_from_env()` to read new env vars
4. **Documentation**: Update README.md configuration section
5. **Default Values**: Ensure sensible defaults in Pydantic models

---

### Configuration Priority Order

Current configuration loading order (from lowest to highest priority):

1. **Pydantic Defaults** - Hardcoded in `settings.py` model classes
2. **YAML Files** - Attempted but files don't exist (dead code)
3. **Environment Variables** - Loaded by Pydantic via `.env` file
4. **Explicit Overrides** - `_override_from_env()` function (currently broken)

**Recommended simplified order**:
1. Pydantic Defaults
2. `.env` file (parsed by Pydantic)
3. Runtime environment variables (highest priority)

---

## ğŸ“‹ Development TODO List

This comprehensive TODO list tracks the refactoring and optimization work for the MediaCrawler MCP Service. Tasks are organized by priority (P0-P2) and grouped into phases.

### **Phase 1: é…ç½®ç³»ç»Ÿé‡æ„ï¼ˆP0 - å…³é”®é—®é¢˜ï¼‰**

#### âœ… 1.1 ç§»é™¤å…¨å±€é…ç½®æ³¨å…¥æœºåˆ¶
- **è·¯å¾„**: `app/config/settings.py:415-458`
- **ä»»åŠ¡**: åˆ é™¤ `MediaCrawlerConfigAdapter.inject_config()` æ–¹æ³•ï¼ˆç›´æ¥ä¿®æ”¹å…¨å±€configå¯¼è‡´å¹¶å‘å†²çªï¼‰
- **å½±å“èŒƒå›´**: `app/core/media_crawler_service.py:191`
- **çŠ¶æ€**: ğŸ”´ å¾…å¤„ç†

#### ğŸ”§ 1.2 å®ç°é…ç½®ä¸Šä¸‹æ–‡ç®¡ç†å™¨
- **æ–°å»ºæ–‡ä»¶**: `app/core/config_context.py`
- **åŠŸèƒ½**:
  - å®ç° `async_media_crawler_config_context()` å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨
  - ä¸´æ—¶ä¿®æ”¹ media_crawler çš„ config æ¨¡å—ï¼Œé€€å‡ºæ—¶è‡ªåŠ¨æ¢å¤
  - æä¾›é…ç½®å¿«ç…§ï¼ˆsnapshotï¼‰å’Œæ¢å¤ï¼ˆrestoreï¼‰åŠŸèƒ½
- **ç¤ºä¾‹ä»£ç ç»“æ„**:
```python
@asynccontextmanager
async def async_media_crawler_config_context(crawler_config: CrawlerConfig):
    original_snapshot = _get_config_snapshot()
    try:
        _inject_config(crawler_config)
        yield
    finally:
        _restore_config_snapshot(original_snapshot)
```
- **çŠ¶æ€**: ğŸ”´ å¾…å¤„ç†

#### ğŸ”§ 1.3 ä¿®å¤ç¯å¢ƒå˜é‡å‘½åä¸ä¸€è‡´
- **è·¯å¾„**: `.env` æ–‡ä»¶ + `app/config/settings.py:333-380`
- **é—®é¢˜**: `.env` ä½¿ç”¨åŒä¸‹åˆ’çº¿ï¼ˆ`APP__PORT`ï¼‰ï¼Œä»£ç è¯»å–å•ä¸‹åˆ’çº¿ï¼ˆ`APP_PORT`ï¼‰
- **ä¿®å¤æ–¹æ¡ˆ**: ç»Ÿä¸€ä½¿ç”¨å•ä¸‹åˆ’çº¿å‘½åï¼ˆç®€å•ç›´è§‚ï¼‰
- **å½±å“æ¡ç›®**:
  - `APP__PORT` â†’ `APP_PORT`
  - `DB__HOST` â†’ `DB_HOST`
  - `REDIS__HOST` â†’ `REDIS_HOST`
  - åˆ é™¤ `.env` ä¸­çš„é‡å¤é…ç½®ï¼ˆè¡Œ39-44ï¼‰
- **çŠ¶æ€**: ğŸ”´ å¾…å¤„ç†

#### ğŸ”§ 1.4 è¡¥å……ç¼ºå¤±çš„é…ç½®å­—æ®µ
- **è·¯å¾„**: `app/config/settings.py:81-97`
- **æ–°å¢å­—æ®µ**:
  - `AppConfig`: æ·»åŠ  `admin_port: int = 9091`
  - `SidecarConfig`: æ·»åŠ  `port: int = 8001`
- **å½±å“æ–‡ä»¶**: `main.py`, `sidecar_main.py`, `admin_main.py`
- **çŠ¶æ€**: ğŸ”´ å¾…å¤„ç†

---

### **Phase 2: API ç«¯ç‚¹ä¼˜åŒ–ï¼ˆP1 - åŠŸèƒ½å®Œå–„ï¼‰**

#### ğŸ”§ 3.1 å®Œå–„ Sidecar Endpoint
- **è·¯å¾„**: `app/api/endpoints/sidecar/sidecar_endpoint.py`
- **å¾…å®ŒæˆåŠŸèƒ½**:
  - Line 150: å®ç°é…ç½®çƒ­æ›´æ–°ï¼ˆ`/config/update`ï¼‰
  - å¢åŠ æ‰¹é‡çˆ¬å–ç«¯ç‚¹ï¼ˆæ”¯æŒå¤šå¹³å°å¹¶è¡Œï¼‰
  - å¢åŠ ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†ç«¯ç‚¹ï¼ˆæŸ¥çœ‹ã€å–æ¶ˆã€é‡è¯•ï¼‰
  - å¢åŠ æ•°æ®å¯¼å‡ºç«¯ç‚¹ï¼ˆJSON/CSV/Excelï¼‰
- **çŠ¶æ€**: ğŸ”´ å¾…å¤„ç†

#### ğŸ”§ 3.2 å®Œå–„ Login Endpoint
- **è·¯å¾„**: `app/api/endpoints/login/login_endpoint.py`
- **å¾…å®ŒæˆåŠŸèƒ½**:
  - Line 100-110: å®ç°çœŸå®çš„ç™»å½•çŠ¶æ€æ£€æŸ¥ï¼ˆ`/status/{platform}`ï¼‰
  - Line 127-138: å®ç°é€€å‡ºç™»å½•é€»è¾‘ï¼ˆ`/logout/{platform}`ï¼‰
  - é›†æˆ `SessionManager` æ£€æŸ¥ä¼šè¯æœ‰æ•ˆæ€§
  - å¢åŠ ä¼šè¯åˆ·æ–°ç«¯ç‚¹ï¼ˆå»¶é•¿æœ‰æ•ˆæœŸï¼‰
- **çŠ¶æ€**: ğŸ”´ å¾…å¤„ç†

#### ğŸ“ 3.3 æ–°å¢ MCP Tools Endpointï¼ˆæ³¨å†Œ21ä¸ªçˆ¬è™«å·¥å…·ï¼‰
- **æ–°å»ºæ–‡ä»¶**: `app/api/endpoints/mcp/mcp_tools_endpoint.py`
- **åŠŸèƒ½**:
  - å°†è¾¹è½¦æœåŠ¡çš„ HTTP API åŒ…è£…ä¸º MCP Tools
  - æ³¨å†Œ 21 ä¸ªå¹³å°ç‰¹å®šå·¥å…·ï¼ˆxhs_search, dy_detail, bili_creator ç­‰ï¼‰
  - ä½¿ç”¨ `MediaCrawlerClient` è°ƒç”¨è¾¹è½¦æœåŠ¡
- **å·¥å…·åˆ—è¡¨**:
  - å°çº¢ä¹¦: `xhs_search`, `xhs_detail`, `xhs_creator`
  - æŠ–éŸ³: `dy_search`, `dy_detail`, `dy_creator`
  - å¿«æ‰‹: `ks_search`, `ks_detail`, `ks_creator`
  - Bç«™: `bili_search`, `bili_detail`, `bili_creator`
  - å¾®åš: `wb_search`, `wb_detail`, `wb_creator`
  - è´´å§: `tieba_search`, `tieba_detail`
  - çŸ¥ä¹: `zhihu_search`, `zhihu_detail`
- **çŠ¶æ€**: ğŸ”´ å¾…å¤„ç†

---

### **Phase 3: éƒ¨ç½²å’Œå®¹å™¨åŒ–ï¼ˆP1 - ç”Ÿäº§å°±ç»ªï¼‰**

#### ğŸ“ 3.1 å®Œå–„ Docker Compose é…ç½®
- **è·¯å¾„**: `deploy/docker-compose.yml`
- **ä¼˜åŒ–ç‚¹**:
  - å¢åŠ å¥åº·æ£€æŸ¥ï¼ˆhealthcheckï¼‰
  - é…ç½®èµ„æºé™åˆ¶ï¼ˆmemory/cpu limitsï¼‰
  - å¢åŠ  Nginx åå‘ä»£ç†æœåŠ¡
  - é…ç½®æ—¥å¿—é©±åŠ¨å’Œå·æŒ‚è½½
- **çŠ¶æ€**: ğŸ”´ å¾…å¤„ç†

---

## ğŸ“Š ä¼˜å…ˆçº§æ€»ç»“

### **ç«‹å³æ‰§è¡Œï¼ˆP0 - å…³é”®é—®é¢˜ï¼‰**
1. âœ… Phase 1: é…ç½®ç³»ç»Ÿé‡æ„ï¼ˆ1.1-1.4ï¼‰

### **æœ¬å‘¨å®Œæˆï¼ˆP1 - é‡è¦åŠŸèƒ½ï¼‰**
2. ğŸ”§ Phase 2: API ç«¯ç‚¹ä¼˜åŒ–
3. ğŸ“ Phase 3: éƒ¨ç½²å’Œå®¹å™¨åŒ–

---

## ğŸ”„ çŠ¶æ€å›¾ä¾‹

- ğŸ”´ å¾…å¤„ç† (Not Started)
- ğŸŸ¡ è¿›è¡Œä¸­ (In Progress)
- ğŸŸ¢ å·²å®Œæˆ (Completed)
- âš ï¸ é˜»å¡ä¸­ (Blocked)
- âœ… å·²éªŒè¯ (Verified)